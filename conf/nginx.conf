
user  mms;

#docs: https://www.cloudpanel.io/blog/nginx-performance/

#lsof -p <pid> | wc -l -> open file descriptors used by a process
#ulimit -n -S: maximum number of open file descriptors per process (SOFT)
#ulimit -n -H: maximum number of open file descriptors per process (HARD: di sopra del quale il limite non può essere aumentato senza modificare i parametri del kernel in /proc)
#i limiti SOFT/HARD possono essere cambiati in /etc/security/limits.conf (vedi lo script scripts/installServer.sh)

#predefinito = 1, la quantità totale di connessioni che il tuo server può gestire sarebbe worker_processes * worker_connections
#auto: regola automaticamente il numero di processi di lavoro Nginx in base ai core disponibili
worker_processes  auto;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

pid        /var/catramms/pids/nginx.pid;


events {
	#vedi commenti sopra
	worker_connections  4096;
}


http {
	include       mime.types;
	default_type  application/octet-stream;

	# reserve 1MB under the name 'uploads' to track uploads
	upload_progress uploads 1m;

	#NGINX inizializza remote_addr con l'IP del Load Balancer.
	#Poichè passiamo dal LB, il vero remote IP è http_x_forwarded_for
	#Il prossimo setting dice a NGINX di sostituire l'IP del LB con http_x_forwarded_for
	#In questo modo nel rate limiting, possiamo usare binary_remote_addr
	#che occupa molto meno spazio
	set_real_ip_from	10.0.0.17; #IP address of test API Loadbalancer
	set_real_ip_from	10.0.0.18; #IP address of test BINARY Loadbalancer
	set_real_ip_from	10.0.0.19; #IP address of test GUI Loadbalancer
	set_real_ip_from	10.0.0.20; #IP address of test DELIVERY Loadbalancer
	set_real_ip_from	10.0.0.21; #IP address of test DELIVERY-PATH Loadbalancer
	set_real_ip_from	10.0.0.22; #IP address of test DELIVERY-F Loadbalancer
	set_real_ip_from	10.0.0.2; #IP address of prod DELIVERY-F Loadbalancer
	set_real_ip_from	10.0.0.4; #IP address of prod DELIVERY-PATH Loadbalancer
	set_real_ip_from	10.0.0.7; #IP address of prod BINARY Loadbalancer
	set_real_ip_from	10.0.0.9; #IP address of prod GUI Loadbalancer
	set_real_ip_from	10.0.0.10; #IP address of prod DELIVERY Loadbalancer
	set_real_ip_from	10.0.0.11; #IP address of prod API Loadbalancer
	set_real_ip_from	172.31.32.0/20; #IP addresses of AWS test e prod Loadbalancer
	set_real_ip_from	172.31.16.0/20; #IP addresses of AWS test e prod Loadbalancer
	set_real_ip_from	172.31.0.0/20; #IP addresses of AWS test e prod Loadbalancer
	real_ip_header		X-Forwarded-For;

	rewrite_log off;

    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
    #                  '$status $body_bytes_sent "$http_referer" '
    #                  '"$http_user_agent" "$http_x_forwarded_for"';
	log_format main '$time_local - $server_name to $upstream_addr - $remote_addr - $remote_user - $upstream_cache_status - $status '
		'- "$request" - $body_bytes_sent - "$http_referer" '
		'- "$http_user_agent" - "$http_x_forwarded_for"';

	log_format error '$time_local - $server_name to $upstream_addr - $remote_addr - $remote_user - $upstream_cache_status - $status '
		'- "$request" - $body_bytes_sent - "$http_referer" '
		'- "$http_user_agent" - "$http_x_forwarded_for"';

	access_log /var/catramms/logs/nginx/access.log main;
	error_log  /var/catramms/logs/nginx/error.log error;

	#https://www.nginx.com/blog/rate-limiting-nginx/
	#10m: shared memory zone 10 megabytes (about 16000 IP addresses takes 1 megabyte in case of binary ip)

	#scenario: cibortv, un canale impiega 1 min. per ripartire, circa 2000 apps continano a richiedere
	#quel canale, le richieste sono ditribuite dal load balancer. La GUI ha smesso di funzionare.
	#Sul singolo API server ho visto 8 richieste contemporane dallo stesso IP servite tutte con successo
	#Nota: parliamo dello stesso IP.
	limit_req_zone $binary_remote_addr zone=mmsAPILimit:10m rate=10r/s;
	limit_req_zone $binary_remote_addr zone=mmsWEBAPILimit:10m rate=10r/s;

	#scenario: vedi sopra
	#Sul singolo GUI server ho visto 3 richieste contemporane dallo stesso IP tutte
	#che fallivano (/catramms/rest/api/checkChannelStatus)
	#Nota: parliamo dello stesso IP.
	limit_req_zone $binary_remote_addr zone=mmsGUILimit:10m rate=10r/s;

	#La conf. sotto indica 10 richieste al secondo, o 1 ogni 100 ms. Se arrivano 50 richieste
	#contemporaneamente, come nel caso del delivery delle 50 picture di mediaItems.xhtml,
	#NGINX inoltra una richiesta al server/proxy e mette le altre 49 in coda.
	#Nota: parliamo dello stesso IP.
	limit_req_zone $binary_remote_addr zone=mmsDeliveryLimit:10m rate=10r/s;
	limit_req_zone $binary_remote_addr zone=mmsBinaryLimit:10m rate=10r/s;
	limit_req_zone $binary_remote_addr zone=mmsEncoderLimit:10m rate=10r/s;

	#path where the responses are to be stored
	#keys_zone size 10m: shared memory zone 10 megabytes (One megabyte zone can store about 8 thousand keys)
	#Cache non acceduta nel periodo specificato da inactive, viene eliminata (vedi commento di proxy_cache_valid in catrammsAPIServer.nginx)
	#Converrebbe avere inactive un "po lungo" per la gestione stale (vedi commento proxy_cache_use_stale in catrammsAPIServer.nginx)
	#inactive 10m: 10 minutes, 1h: 1 ora
	fastcgi_cache_path /var/catramms/cache/nginx/api levels=1:2 keys_zone=api_cache:100m max_size=1g inactive=1h;
	proxy_cache_path /var/catramms/cache/nginx/webapi levels=1:2 keys_zone=webapi_cache:100m max_size=1g inactive=1h;

	server_names_hash_bucket_size 64;

	#log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
	#                  '$status $body_bytes_sent "$http_referer" '
	#                  '"$http_user_agent" "$http_x_forwarded_for"';

	#access_log  logs/access.log  main;

	sendfile        on;
    #tcp_nopush     on;

	#keepalive_timeout  0;
	keepalive_timeout  65;

	#gzip  on;

	include /opt/catramms/nginx/conf/sites-enabled/*;

}
